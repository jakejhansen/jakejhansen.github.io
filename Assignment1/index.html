<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>D3: Line chart</title>
    <script type="text/javascript" src="d3.js"></script>
    <style type="text/css">
        .line {
            fill: none;
            stroke: teal;
            stroke-width: .5;
        }

        .regline {
            fill: none;
            stroke: black;
            stroke-width: 4;
        }

        body {
            width: 700px;
        }
    </style>
</head>

<body>
    <h2 id="part1daostchapter2questions">Part 1: DAOST Chapter 2 Questions</h2>

    <ul>
        <li>
            <p>Explain in your own words the point of the jitter plot.</p>

            <ul>
                <li>
                    <span style="color : blue"> A normal scatter plot can have many overlapping points if each observation is not unique, so we have no way of telling if each point is just representing 1 or 1000 observations.
                        A jitter plot can displace overlaying points so that we can actually see if more points a lying
                        on top of each other. It does this by adding a little random value to the x- and y coordinates of every point, displacing them a slight bit.</span>
                </li>
            </ul>
        </li>

        <li>
            <p>Explain in your own words the point of figure 2-3. (I'm going to skip saying "in your own words" going forward,
                but I hope you get the point; I expect all answers to be in your own words).</p>

            <ul>
                <li>
                    <span style="color : blue"> Here is it shown, that the placement of the bins is quite important in the representation of our histogram.
                        The first histogram shows that there are en equal number of datapoints in the intervals [1, 2], [2,3] and the second
                        shows that most points are within [1.5, 2.5] with very few are the edges. This could also have been
                        fixed by just choosing a smaller width. </span>
                </li>
            </ul>
        </li>

        <li>
            <p>The author of DAOST (Philipp Janert) likes KDEs (and think they're better than histograms). And I don't. I didn't
                give a detailed explanation in the video, but now that works to my advantage. I'll ask you guys to think
                about this and thereby create an excellent exercise: When can KDEs be misleading?</p>

            <ul>
                <li>
                    <span style="color : blue"> KDEs tend to average or smooth the data to form a more continious representation so we will have to think
                        of a case where we don't want this. Often when we have discrete data it might be unsuitable
                        to smooth the data, for instance in the case of throwing a dice. Also you are altering your data with
                        an KDE so you don't have that 1:1 relationship between your dataset and your visualization. For instance a histogram will
                        CLEARLY show the proportion of datapoints in interval [x1, x2], and a KDE will just show a continious
                        line that has been smoothed according to some parameter. </span>
                </li>
            </ul>
        </li>

        <li>
            <p>I've discussed some strengths of the CDF - there are also weaknesses. Janert writes "[CDFs] have less intuitive
                appeal than histograms of KDEs". What does he mean by that?</p>

            <ul>
                <li>
                    <span style="color : blue"> It is a bit harder to read because you don't see the data itself, you see it through a function. If you don't pay attention you might just
                        think that the end values are bigger than the beginning when we really want to be looking at the
                        difference over the intervals in the CDF to see how much data is condensed in a certain interval. Generally when using CDF it's a good idea to add a comment as to what 
                    exactly we are looking at and what part of the CDF we need to pay attention to; what is the story you are telling with the CDF and how can it be seen?</span>
                </li>
            </ul>
        </li>

        <li>
            <p>What is a
                <em>Quantile plot</em>? What is it good for. </p>

            <ul>
                <li>
                    <span style="color : blue"> It is just a CDF with the axes reversed. So we get our variable as a function of percentage. In the example in the book:
                        What is the response time for the 50% percentile? (average). This can be read directly off the figure, so it says something about how our data is distributed and how skewed it is.</span>
                </li>
            </ul>
        </li>

        <li>
            <p>How is a
                <em>Probablity plot</em> defined? What is it useful for? Have you ever seen one before?</p>

            <ul>
                <li>
                    <span style="color : blue"> Here we essentially just plot the data againt a gaussian distribution along a straighe line. That way
                        we can easily check if the data is truly gaussian distributed. We can also use other probability
                        distributions and we do so to determine graphically if data stems from a specific underlying distribution. For instance for checking the assumption about normality of the residuals. 
                    </span>
                </li>
            </ul>
        </li>

        <li>
            <p>One of the reasons I like DAOST is that Janert is so suspicious of mean, median, and related summary statistics.
                Explain why one has to be careful when using those - and why visualization of the full data is always better.
            </p>

            <ul>
                <li>
                    <span style="color : blue"> The distribution of data has to be one with a sharp peak and where it actually makes sense to use these.
                        One outlier can easily ruin the party and render these statistics useless. Also non symetric distributions
                        will not work, the mean will just be scewed and the variance also. If using these you always have to visualize the data, because very differently distributed data can have the exact same summary statistics.
                    An example is Anscombeâ€™s quartet shown on figure 3-15 </span>
                </li>
            </ul>
        </li>

        <li>
            <p>I love box plots. When are box plots most useful?</p>

            <ul>
                <li>
                    <span style="color : blue"> Box plots are best in pairs, i.e for comparing different variables and distributions or datasets. They can very quickly give a nice overview of your dataset and see if all your variables conform to the same distribution or if they are very different.</span>
                </li>
            </ul>
        </li>

        <li>
            <p>The book doesn't mention
                <a href="https://en.wikipedia.org/wiki/Violin_plot">violin plots</a>. Are those better or worse than box plots? Why?</p>

            <ul>
                <li>
                    <span style="color : blue"> They are essentially better - They show the distribution instead of just a box, however they are not
                        very popular so getting your message across can be harder depending on the nature of the audience. It's rarely a good idea to put too much information into a plot, and if you decide
                    to use it, you HAVE to also give an explanation of the violin plot because they are relatively unknown. Having two seperate plots are in most cases a better idea. </span>
                </li>
            </ul>
        </li>
    </ul>




    <h2 id="part2daostchapter3questions">Part 2: DAOST Chapter 3 Questions</h2>

    <ul>
        <li>
            <p>Looking at Fig 3-1, Janert writes "the data itself shows clearly that the amount of random noise in the data
                is small". What do you think his argument is?</p>

            <ul>
                <li>
                    <span style="color : blue"> Visually you can draw a nice and simple curve that goes through all the data points. If we had a lot
                        of noise, the points would be jittered around such a curve so that every datapoint had a distance
                    <b>d</b> from the curve. The larger the noise the larger the <b>d</b> from the points to the curve describing
                        the relationship. This distance if often what we try to minimize when doing line-fitting i.e minimize
                        the root mean square error. </span>
                </li>
            </ul>
        </li>

        <li>
            <p>Can you think of a real-world example of a multivariate relationship like the one in Fig 3-3 (lower right panel)?</p>

            <ul>
                <li>
                    <span style="color : blue"> It could be financial assets that depends differently on different input variables. For instance the
                        plot could despict two assets, both which in the start falls in correlation with a GDP-variable but
                        then one assets takes off because it is strongly correlated with a key number in its industry. The
                        other asset is not in the same industry and as such is not correlated with this variable making them diverge </span>
                </li>
            </ul>
        </li>

        <li>
            <p>What are the two methods Janert metions for smoothing noisy data? Can you think of other ones?</p>

            <ul>
                <li>
                    <p>
                        <span style="color : blue"> Splines: We sticht piecewise polynomials together, controlling how smooth we want the curve and how
                            close we want it to fit the data. Splines needs to be tuned to the problem at hand. One nice
                            thing is that we can weigh each datapoint, giving more weights to points that we know are accurate
                            and less weight to those that we don't trust as much.</span>
                    </p>
                </li>

                <li>
                    <p>
                        <span style="color : blue"> LOESS: This method is basically a local linear regression (usually), where we take all the data and
                            weigh it using a filter with a specified width before computing the linear regression. A large
                            width effectively means that we take a wider range of data points into consideration for the smoothed valued
                            at our desired location and a smaller one means we take less. So using large kernels we get
                            a more global trend, using a smaller one yields a more local trend. The LOESS is quite expensive
                            because we have to filter all data with the kernel for each smoothed value that needs to be computed.
                        </span>
                    </p>
                </li>

                <li>
                    <p>
                        <span style="color : blue"> Other methods could be a standard running average or exponential smoothing (smooth each value with
                            its previous values using an exponentially decreasing weight). </span>
                    </p>
                </li>
            </ul>
        </li>

        <li>
            <p>What are residuals? Why is it a good idea to plot the residuals of your fit?</p>

            <ul>
                <li>
                    <span style="color : blue"> Residuals are the remainder when you subtract the datapoints from your model, i.e subtract
                        your estimate from the ground trouth. For an appropiate model, we would like to see symetrically and
                        uncorrelated residuals. If you have uncorrelated residuals, the error in your model is due to noise,
                        if you have correlated residuals it means that you have a SYSTEMATIC error in your model. So there
                        are factors in your data-set which your model does not take into account. We should always plot the
                        residual to both see their magnitude but most importantly their structure. They are also usefull for outlier
                        detection, i.e if you have a few residuals that are very far from the others it could mean that the
                        corrosponding datapoint is an outlier in your dataset.</span>
                </li>
            </ul>
        </li>

        <li>
            <p>Explain in your own words the point of the smooth tube in figure 3-7.</p>

            <ul>
                <li>
                    <span style="color : blue"> It is to show both a smoothed line and also its confidence interval. The upper and lower bound of this
                        confidence interval is made using only the datapoints with positive contributions for the upper confidence interval and
                        only residual with negative contribution for the lower bound. So in essence most of the datapoints
                        should lie between the upper and lower confidence interval.</span>
                </li>
            </ul>
        </li>

        <li>
            <p>What kind of relationships will a semi-log plot help you discover?</p>

            <ul>
                <li>
                    <span style="color : blue"> A semi-log plot will clearly show us if our data has an exponential relationship on one axis because in
                        a semi-log plot this will be shown as a straight line. Also all relative change is shown as the same
                        size so it is the relative change that is in focus, not the absolute.</span>
                </li>
            </ul>
        </li>

        <li>
            <p>What kind of functions will loglog plots help you see?</p>

            <ul>
                <li>
                    <span style="color : blue"> A loglog plot will show us power-relations as straight lines. Where the slope of the lines gives us the
                        power-factor between the variables. I.e slope 2 corresponds to y = x^2. Note that we generally use
                        single and double log as a tool to show data which are far apart (spanning many magnitues) in one
                        plot without having one section of the plot being completely dominated by larger values. And this
                        generally happens when we have power and exponential relationships in our data, meaning that many
                        points will confined in a small range and then there will be large gaps spanning to the biggest points
                        in the dataset. </span>
                </li>
            </ul>
        </li>

        <li>
            <p>What the h#ll is
                <em>banking</em> and what element from our visual system does it use to help us see patterns? What are potential
                problems with banking?</p>

            <ul>
                <li>
                    <span style="color : blue"> Banking is the process of adjusting the size and range of your axis such that lines in the graph are
                        at approximately 45 degrees. Humans are great at recognized slopes and lines, generally useful for
                        estimating trajectories and so on, however very small changes in slope are hard for us to see. The
                        difference between 1 degree and 2 degrees are very hard to differentiate, but the difference between
                        45 and 90 degrees are no problem. The problem with banking is, that it can become too extreme, shrinking
                        one axis to almost nothing but on the other hand we will do banking manually and not by some algorithm
                        so we will indeed fit the axis to whatever we think represents the structure of our data the best.
                        Another problem is, that humans seem to prefer the 4:3 format and banking your graph can take
                        your graphs away from this.</span>
                </li>
            </ul>
        </li>

        <li>
            <p>I think figure 3-14 makes an important point about linear fits that is rarely made. What is it? </p>

            <ul>
                <li>
                    <span style="color : blue">The point is, that the linear fit is not the best summarizer of data but instead a good predictor of
                        one variable in response to another. It essentially shows that you can get two different optimal
                        fits by either fitting <b>x</b> as function of <b>y</b>, or <b>y</b> as function of <b>x</b>. So when we use regression, it should
                        be as a means of predicting data and not as a way to summarize it. </span>
                </li>
            </ul>
        </li>

        <li>
            <p>Summarize the discussion of
                <em>Graphical Analysis</em> and
                <em>Presentation Graphics</em> on pp. 68-69 in your own words.</p>

            <ul>
                <li>
                    <span style="color : blue"> Here he discusses the difference between graphical analysis (visualizing the dataset in different ways
                        to use the human eye to interpret pattern and correlations) and presenting the data to an audience.
                        When we do graphical anaylsis, we seek to find an unknown structure to the data and are therefore
                        exploring the data. When we present it, we already know the results from previous anaylsis, now we
                        want to communicate this result as best as possible to the reader. We need to make the graphs talk
                        for themselves so they need as little text as possible for explaining, right font size, line thickness, simplicity
                        and so on to convey the result of our analysis. </span>
                </li>
            </ul>
        </li>
    </ul>

    <h2>Viz 1</h2>
    <p>This is a reproduction of
        <a href="http://iquantny.tumblr.com/post/129373499164/this-is-quantifiably-the-best-month-to-go-to-the">http://iquantny.tumblr.com/post/129373499164/this-is-quantifiably-the-best-month-to-go-to-the</a>
    </p>
    <p>As part of a homework assignment, I ask my students at Pratt to go out and chart something of interest to them, and
        <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fkvsavarese&amp;t=NmE2YmYyYjU4NTI3MTFhYWFiMWE1ZjFhNzc1NmUzMmE0ZDQ4OGM2NSwxeHM2a1phNg%3D%3D&amp;b=t%3A5jlxwUw4OZ-2SbgNDPgKMQ&amp;p=http%3A%2F%2Fiquantny.tumblr.com%2Fpost%2F129373499164%2Fthis-is-quantifiably-the-best-month-to-go-to-the&amp;m=1">Katherine Savarese</a> came back with a simple chart about farmers markets that I loved- it inspired this post.</p>
    <p>You probably know that farmers markets are a staple across
        <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.grownyc.org%2Ffiles%2Fgmkt%2Fmap.pdf&amp;t=MGM4YmRjZjQ2ZmFmYzBiYmMzMmY5NDU2MTdiNzMzMmYyOWQ5YjQ2ZSwxeHM2a1phNg%3D%3D&amp;b=t%3A5jlxwUw4OZ-2SbgNDPgKMQ&amp;p=http%3A%2F%2Fiquantny.tumblr.com%2Fpost%2F129373499164%2Fthis-is-quantifiably-the-best-month-to-go-to-the&amp;m=1">all five boroughs</a> of New York City, but September happens to be a very special month. Why is that? &nbsp;Well,
        it turns out September is the month with the most unique types of fresh produce- forty three to be exact.</p>
    <p>To show the current offerings, we charted how many types of fruits and vegetables are available by month, and showed
        if they were fresh or from storage.         &nbsp;</p>
    <select id="produce_select">
        <option value="0">Fresh Fruit</option>
        <option value="1">Fresh Vegetable</option>
        <option value="2">Storage Fruit</option>
        <option value="3">Storage Vegetable</option>
    </select>
    <p> </p>
    <p id="graph2"></p>
    <script src="produce.js" type="text/javascript"></script>

    <h2>Viz 2</h2>
    <p>Below is shown a figure of the winning times for the boston marathon. A standard linear regression line has been fitted
        to all data up to and including 1990 for both men and women and it estimates that women will overtake men in the
        marathon in 1991. This shows the danger of using linear regression as a tool to summarize the data since it puts
        equal weight on all the datapoints not taking into account the local trend that we are seeing at the end of our datapoints.
        Clearly the winning times for women are converging, but this is not visible from the linear regression only from
        visually inspecting the data. </p>
    <select id="runners_select">
        <option value="-1">All Runners</option>
        <option value="0">Men</option>
        <option value="1">Women</option>
    </select>
    <p id="graph1"></p>

    <script src="runners.js" type="text/javascript"></script>

</body>

</html>
